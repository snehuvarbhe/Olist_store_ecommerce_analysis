{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np   # For numerical operations and handling arrays\n",
    "import matplotlib.pyplot as plt  # For creating visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary CSV files into pandas DataFrames\n",
    "\n",
    "# Orders dataset containing details of each order placed by customers\n",
    "orders = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\olist_orders_dataset.csv\")\n",
    "\n",
    "# Products dataset containing details of each product listed in the system\n",
    "products = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\olist_products_dataset.csv\")\n",
    "\n",
    "# Customers dataset containing information about the customers who placed the orders\n",
    "customers = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\olist_customers_dataset.csv\")\n",
    "\n",
    "# Sellers dataset containing information about the sellers offering products on the platform\n",
    "seller = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\olist_sellers_dataset.csv\")\n",
    "\n",
    "# Geolocation dataset containing the geographical location details of sellers and customers\n",
    "geo_loc = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\olist_geolocation_dataset.csv\")\n",
    "\n",
    "# Order items dataset containing details of items in each order\n",
    "items = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\olist_order_items_dataset.csv\")\n",
    "\n",
    "# Payments dataset containing payment details for each order\n",
    "payments = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\olist_order_payments_dataset.csv\")\n",
    "\n",
    "# Reviews dataset containing the feedback and reviews from customers for the orders they received\n",
    "reviews = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\olist_order_reviews_dataset.csv\")\n",
    "\n",
    "# Product category dataset containing the translation of product categories\n",
    "product_category = pd.read_csv(r\"D:\\git_projects\\retail_data_analysis\\dataset\\product_category_name_translation.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'orders' DataFrame\n",
    "orders.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',\n",
      "       'order_approved_at', 'order_delivered_carrier_date',\n",
      "       'order_delivered_customer_date', 'order_estimated_delivery_date'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       99441 non-null  object        \n",
      " 1   customer_id                    99441 non-null  object        \n",
      " 2   order_status                   99441 non-null  object        \n",
      " 3   order_purchase_timestamp       99441 non-null  datetime64[ns]\n",
      " 4   order_approved_at              99281 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   97658 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  96476 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  99441 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](5), object(3)\n",
      "memory usage: 6.1+ MB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " order_id                         0.000000\n",
      "customer_id                      0.000000\n",
      "order_status                     0.000000\n",
      "order_purchase_timestamp         0.000000\n",
      "order_approved_at                0.160899\n",
      "order_delivered_carrier_date     1.793023\n",
      "order_delivered_customer_date    2.981668\n",
      "order_estimated_delivery_date    0.000000\n",
      "dtype: float64\n",
      "\n",
      "Unique values in order_status: ['delivered' 'canceled']\n",
      "\n",
      "Shape: (96461, 8) \n",
      "\n",
      "Total unique orders: 96461\n",
      "\n",
      "Total unique customers: 96461\n",
      "\n",
      " order_status\n",
      "delivered    96455\n",
      "canceled         6\n",
      "Name: count, dtype: int64\n",
      "Unique entries: 96461\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the 'orders' DataFrame\n",
    "print(\"Columns are:\", orders.columns)\n",
    "\n",
    "# Print the data types of each column in the 'orders' DataFrame\n",
    "orders.dtypes\n",
    "\n",
    "# List of date columns that need to be converted to datetime format\n",
    "date_columns = ['order_purchase_timestamp', 'order_approved_at', \n",
    "                'order_delivered_carrier_date', 'order_delivered_customer_date', \n",
    "                'order_estimated_delivery_date']\n",
    "\n",
    "# Loop through each date column and convert the values to datetime format\n",
    "# Any invalid date format will be coerced to NaT (Not a Time)\n",
    "for col in date_columns:\n",
    "    orders[col] = pd.to_datetime(orders[col], errors='coerce')\n",
    "\n",
    "# Display the summary of the DataFrame, including data types and non-null counts\n",
    "orders.info()\n",
    "\n",
    "# Print the number of duplicate records in the 'orders' DataFrame\n",
    "print(\"\\nNumber of duplicate records:\", orders.duplicated().sum())\n",
    "\n",
    "# Print the percentage of null values in each column of the 'orders' DataFrame\n",
    "print(\"\\nPercentage of null values in each column:\\n\", orders.isnull().mean() * 100)\n",
    "\n",
    "# Drop all rows with null values from the DataFrame\n",
    "orders.dropna(inplace=True)\n",
    "\n",
    "# Get the minimum and maximum dates from the specified date columns\n",
    "orders[date_columns].agg(['min', 'max'])\n",
    "\n",
    "# Print the unique values in the 'order_status' column\n",
    "print(\"\\nUnique values in order_status:\", orders['order_status'].unique())\n",
    "\n",
    "# Print the shape (number of rows and columns) of the DataFrame\n",
    "print(\"\\nShape:\", orders.shape, \"\\n\")\n",
    "\n",
    "# Print the total unique orders\n",
    "print(\"Total unique orders:\", orders['order_id'].nunique())\n",
    "\n",
    "# Print the total unique customers\n",
    "print(\"\\nTotal unique customers:\", orders['customer_id'].nunique())\n",
    "\n",
    "# Print the counts of each unique value in the 'order_status' column\n",
    "print(\"\\n\",orders['order_status'].value_counts())\n",
    "\n",
    "# Calculate the time difference in seconds between 'order_approved_at' and 'order_purchase_timestamp' in hr\n",
    "\n",
    "orders['order_confirm_days'] = (\n",
    "    (orders['order_approved_at'] - orders['order_purchase_timestamp'])  # Subtract to get timedelta\n",
    "    .dt.total_seconds()  # Convert timedelta to total seconds\n",
    "    / (60 * 60 * 24)  # Convert seconds to hours\n",
    ")\n",
    "\n",
    "#print the unique entries\n",
    "print(\"Unique entries:\",orders['order_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_length</th>\n",
       "      <th>product_description_length</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>40.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>artes</td>\n",
       "      <td>44.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id product_category_name  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5            perfumaria   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f                 artes   \n",
       "2  96bd76ec8810374ed1b65e291975717f         esporte_lazer   \n",
       "\n",
       "   product_name_length  product_description_length  product_photos_qty  \\\n",
       "0                 40.0                       287.0                 1.0   \n",
       "1                 44.0                       276.0                 1.0   \n",
       "2                 46.0                       250.0                 1.0   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
       "0             225.0               16.0               10.0              14.0  \n",
       "1            1000.0               30.0               18.0              20.0  \n",
       "2             154.0               18.0                9.0              15.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'products' DataFrame\n",
    "products.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['product_id', 'product_category_name', 'product_name_length',\n",
      "       'product_description_length', 'product_photos_qty', 'product_weight_g',\n",
      "       'product_length_cm', 'product_height_cm', 'product_width_cm'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_length         32341 non-null  Int32  \n",
      " 3   product_description_length  32341 non-null  Int32  \n",
      " 4   product_photos_qty          32341 non-null  Int32  \n",
      " 5   product_weight_g            32949 non-null  float32\n",
      " 6   product_length_cm           32949 non-null  float32\n",
      " 7   product_height_cm           32949 non-null  float32\n",
      " 8   product_width_cm            32949 non-null  float32\n",
      "dtypes: Int32(3), float32(4), object(2)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " product_id                    0.000000\n",
      "product_category_name         1.851234\n",
      "product_name_length           1.851234\n",
      "product_description_length    1.851234\n",
      "product_photos_qty            1.851234\n",
      "product_weight_g              0.006070\n",
      "product_length_cm             0.006070\n",
      "product_height_cm             0.006070\n",
      "product_width_cm              0.006070\n",
      "dtype: float64\n",
      "\n",
      "shape: (32340, 9) \n",
      "\n",
      "Unique entries: 32340\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the 'products' DataFrame\n",
    "print(\"Columns are:\", products.columns)\n",
    "\n",
    "# Display the data types of each column in the 'products' DataFrame\n",
    "products.dtypes\n",
    "\n",
    "# List of columns that should be converted to integers (product-related metrics)\n",
    "int_columns = ['product_name_length', 'product_description_length', 'product_photos_qty']\n",
    "\n",
    "# Loop through each column in 'int_columns', convert to numeric, handle errors, and cast to integer\n",
    "for col in int_columns:\n",
    "    # Convert the column to numeric, coerce errors (set invalid parsing to NaN)\n",
    "    products[col] = pd.to_numeric(products[col], errors='coerce').astype('Int32')\n",
    "\n",
    "# List of columns that should be converted to float type (product measurements)\n",
    "int_columns = ['product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
    "\n",
    "# Loop through each column in 'int_columns', convert to numeric, handle errors, and cast to float\n",
    "for col in int_columns:\n",
    "    # Convert the column to numeric, coerce errors (set invalid parsing to NaN)\n",
    "    products[col] = pd.to_numeric(products[col], errors='coerce').astype('float32')\n",
    "\n",
    "# Display the summary of the DataFrame, including the data types, non-null counts, etc.\n",
    "products.info()\n",
    "\n",
    "# Print the number of duplicate rows in the DataFrame\n",
    "print(\"\\nNumber of duplicate records:\", products.duplicated().sum())\n",
    "\n",
    "# Print the percentage of null values in each column\n",
    "print(\"\\nPercentage of null values in each column:\\n\", products.isnull().mean() * 100)\n",
    "\n",
    "# Drop rows with any null values from the DataFrame\n",
    "products.dropna(inplace=True)\n",
    "\n",
    "# Print the shape of the DataFrame after dropping rows with null values\n",
    "print(\"\\nshape:\", products.shape, \"\\n\")\n",
    "\n",
    "#print the unique entries\n",
    "print(\"Unique entries:\",products['product_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'customers' DataFrame\n",
    "customers.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['customer_id', 'customer_unique_id', 'customer_zip_code_prefix',\n",
      "       'customer_city', 'customer_state'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  Int32 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: Int32(1), object(4)\n",
      "memory usage: 3.5+ MB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " customer_id                 0.0\n",
      "customer_unique_id          0.0\n",
      "customer_zip_code_prefix    0.0\n",
      "customer_city               0.0\n",
      "customer_state              0.0\n",
      "dtype: float64\n",
      "\n",
      "Unique values in customer state: ['SP' 'SC' 'MG' 'PR' 'RJ' 'RS' 'PA' 'GO' 'ES' 'BA' 'MA' 'MS' 'CE' 'DF'\n",
      " 'RN' 'PE' 'MT' 'AM' 'AP' 'AL' 'RO' 'PB' 'TO' 'PI' 'AC' 'SE' 'RR']\n",
      "\n",
      "Shape: (99441, 5) \n",
      "\n",
      "Unique entries: 99441\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the 'customers' DataFrame\n",
    "print(\"Columns are:\", customers.columns)\n",
    "\n",
    "# Display the data types of each column in the 'customers' DataFrame\n",
    "customers.dtypes\n",
    "\n",
    "# List of columns that should be converted to numeric values\n",
    "cust_columns = ['customer_zip_code_prefix']\n",
    "\n",
    "# Loop through each column in the 'cust_columns' list\n",
    "for col in cust_columns:\n",
    "    # Convert the specified column to numeric, coercing errors to NaN\n",
    "    # Then convert it to 'Int32' type\n",
    "    customers[col] = pd.to_numeric(customers[col], errors='coerce').astype('Int32')\n",
    "\n",
    "# Display information about the DataFrame including column data types, non-null counts, and memory usage\n",
    "customers.info()\n",
    "\n",
    "# Print the number of duplicate records in the 'customers' DataFrame\n",
    "print(\"\\nNumber of duplicate records:\", customers.duplicated().sum())\n",
    "\n",
    "# Print the percentage of null values in each column of the 'customers' DataFrame\n",
    "print(\"\\nPercentage of null values in each column:\\n\", customers.isnull().mean() * 100)\n",
    "\n",
    "# Print the unique values in the 'customer_state' column\n",
    "print(\"\\nUnique values in customer state:\", customers['customer_state'].unique())\n",
    "\n",
    "# Print the shape (number of rows and columns) of the 'customers' DataFrame\n",
    "print(\"\\nShape:\", customers.shape, \"\\n\")\n",
    "\n",
    "#print the unique entries\n",
    "print(\"Unique entries:\",customers['customer_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix     seller_city  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023        campinas   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844      mogi guacu   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031  rio de janeiro   \n",
       "\n",
       "  seller_state  \n",
       "0           SP  \n",
       "1           SP  \n",
       "2           RJ  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'seller' DataFrame\n",
    "seller.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['seller_id', 'seller_zip_code_prefix', 'seller_city', 'seller_state'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   Int32 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: Int32(1), object(3)\n",
      "memory usage: 87.8+ KB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " seller_id                 0.0\n",
      "seller_zip_code_prefix    0.0\n",
      "seller_city               0.0\n",
      "seller_state              0.0\n",
      "dtype: float64\n",
      "\n",
      "Unique values in seller state: ['SP' 'RJ' 'PE' 'PR' 'GO' 'SC' 'BA' 'DF' 'RS' 'MG' 'RN' 'MT' 'CE' 'PB'\n",
      " 'AC' 'ES' 'RO' 'PI' 'MS' 'SE' 'MA' 'AM' 'PA']\n",
      "\n",
      "shape: (3095, 4) \n",
      "\n",
      "Unique entries: 3095\n"
     ]
    }
   ],
   "source": [
    "# Display the column names of the 'seller' DataFrame\n",
    "print(\"Columns are:\", seller.columns)\n",
    "\n",
    "# Display the data types of each column in the 'seller' DataFrame\n",
    "seller.dtypes\n",
    "\n",
    "# List of columns that need to be converted to numeric types\n",
    "seller_columns = ['seller_zip_code_prefix']\n",
    "\n",
    "# Loop through each column in 'seller_columns' to convert the data type\n",
    "for col in seller_columns:\n",
    "    # Convert column to numeric, coercing errors into NaN, then cast it to 'Int32' (nullable integer type)\n",
    "    seller[col] = pd.to_numeric(seller[col], errors='coerce').astype('Int32')\n",
    "\n",
    "# Display summary information about the 'seller' DataFrame (e.g., number of non-null entries, data types)\n",
    "seller.info()\n",
    "\n",
    "# Print the number of duplicate records in the 'seller' DataFrame\n",
    "print(\"\\nNumber of duplicate records:\", seller.duplicated().sum())\n",
    "\n",
    "# Calculate and print the percentage of missing (null) values in each column of the 'seller' DataFrame\n",
    "print(\"\\nPercentage of null values in each column:\\n\", seller.isnull().mean() * 100)\n",
    "\n",
    "# Display the unique values present in the 'seller_state' column\n",
    "print(\"\\nUnique values in seller state:\", seller['seller_state'].unique())\n",
    "\n",
    "# Display the shape (number of rows and columns) of the 'seller' DataFrame\n",
    "print(\"\\nshape:\", seller.shape, \"\\n\")\n",
    "\n",
    "#print the unique entries\n",
    "print(\"Unique entries:\",seller['seller_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>-23.55</td>\n",
       "      <td>-46.64</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.55</td>\n",
       "      <td>-46.64</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041</td>\n",
       "      <td>-23.54</td>\n",
       "      <td>-46.64</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                         1037           -23.55           -46.64   \n",
       "1                         1046           -23.55           -46.64   \n",
       "2                         1041           -23.54           -46.64   \n",
       "\n",
       "  geolocation_city geolocation_state  \n",
       "0        sao paulo                SP  \n",
       "1        sao paulo                SP  \n",
       "2        sao paulo                SP  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'geo locations' DataFrame\n",
    "geo_loc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng',\n",
      "       'geolocation_city', 'geolocation_state'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19015 entries, 0 to 19014\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   geolocation_zip_code_prefix  19015 non-null  Int32  \n",
      " 1   geolocation_lat              19015 non-null  float32\n",
      " 2   geolocation_lng              19015 non-null  float32\n",
      " 3   geolocation_city             19015 non-null  object \n",
      " 4   geolocation_state            19015 non-null  object \n",
      "dtypes: Int32(1), float32(2), object(2)\n",
      "memory usage: 538.6+ KB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " geolocation_zip_code_prefix    0.0\n",
      "geolocation_lat                0.0\n",
      "geolocation_lng                0.0\n",
      "geolocation_city               0.0\n",
      "geolocation_state              0.0\n",
      "dtype: float64\n",
      "\n",
      "shape: (19015, 5) \n",
      "\n",
      "Unique entries: 19015\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the geo_loc DataFrame\n",
    "print(\"Columns are:\", geo_loc.columns)\n",
    "\n",
    "# Display the data types of each column\n",
    "geo_loc.dtypes\n",
    "\n",
    "# Define a list of columns that should be converted to numeric (geolocation_zip_code_prefix)\n",
    "geo_columns1 = ['geolocation_zip_code_prefix']\n",
    "for col in geo_columns1:\n",
    "    # Convert the column to numeric, using 'coerce' to handle errors (convert invalid values to NaN)\n",
    "    # Then, cast the column as Int32 to allow for nullable integers\n",
    "    geo_loc[col] = pd.to_numeric(geo_loc[col], errors='coerce').astype('Int32')\n",
    "\n",
    "# Define a list of columns that should be converted to float (geolocation_lat, geolocation_lng)\n",
    "geo_columns2 = ['geolocation_lat', 'geolocation_lng']\n",
    "for col in geo_columns2:\n",
    "    # Convert the column to numeric, using 'coerce' to handle errors (convert invalid values to NaN)\n",
    "    # Then, cast the column as float32 to save memory\n",
    "    geo_loc[col] = pd.to_numeric(geo_loc[col], errors='coerce').astype('float32')\n",
    "\n",
    "# Display the summary information about the DataFrame, including data types, non-null counts, etc.\n",
    "geo_loc.info()\n",
    "\n",
    "# Print the number of duplicate records in the geo_loc DataFrame\n",
    "print(\"\\nNumber of duplicate records:\", geo_loc.duplicated().sum())\n",
    "\n",
    "# Drop duplicate records from the DataFrame in place\n",
    "geo_loc.drop_duplicates(inplace=True)\n",
    "\n",
    "# Print the percentage of null values in each column of the DataFrame\n",
    "print(\"\\nPercentage of null values in each column:\\n\", geo_loc.isnull().mean() * 100)\n",
    "\n",
    "# Print the shape of the DataFrame (rows, columns)\n",
    "print(\"\\nshape:\", geo_loc.shape, \"\\n\")\n",
    "\n",
    "#print the unique entries\n",
    "print(\"Unique entries:\",geo_loc['geolocation_zip_code_prefix'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>shipping_limit_date</th>\n",
       "      <th>price</th>\n",
       "      <th>transport_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>19-09-2017 09:45</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>03-05-2017 11:05</td>\n",
       "      <td>239.9</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>18-01-2018 14:48</td>\n",
       "      <td>199.0</td>\n",
       "      <td>17.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  order_item_id  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
       "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
       "2  000229ec398224ef6ca0657da4fc703e              1   \n",
       "\n",
       "                         product_id                         seller_id  \\\n",
       "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
       "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
       "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
       "\n",
       "  shipping_limit_date  price  transport_cost  \n",
       "0    19-09-2017 09:45   58.9           13.29  \n",
       "1    03-05-2017 11:05  239.9           19.93  \n",
       "2    18-01-2018 14:48  199.0           17.87  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'items' DataFrame\n",
    "items.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['order_id', 'order_item_id', 'product_id', 'seller_id',\n",
      "       'shipping_limit_date', 'price', 'transport_cost'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snehu\\AppData\\Local\\Temp\\ipykernel_9864\\624240412.py:17: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  items[col] = pd.to_datetime(items[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   order_id             112650 non-null  object        \n",
      " 1   order_item_id        112650 non-null  Int32         \n",
      " 2   product_id           112650 non-null  object        \n",
      " 3   seller_id            112650 non-null  object        \n",
      " 4   shipping_limit_date  112650 non-null  datetime64[ns]\n",
      " 5   price                112650 non-null  float32       \n",
      " 6   transport_cost       112650 non-null  float32       \n",
      "dtypes: Int32(1), datetime64[ns](1), float32(2), object(3)\n",
      "memory usage: 4.8+ MB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " order_id               0.0\n",
      "order_item_id          0.0\n",
      "product_id             0.0\n",
      "seller_id              0.0\n",
      "shipping_limit_date    0.0\n",
      "price                  0.0\n",
      "transport_cost         0.0\n",
      "dtype: float64\n",
      "\n",
      "shape: (112650, 7) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the DataFrame\n",
    "print(\"Columns are:\", items.columns)\n",
    "\n",
    "# Print the data types of each column in the DataFrame\n",
    "items.dtypes\n",
    "\n",
    "# Define a list of columns that need to be converted to numeric (with coercion for errors)\n",
    "items_columns1 = ['order_item_id']\n",
    "for col in items_columns1:\n",
    "    # Convert specified columns to numeric and handle errors by setting them to NaN, then cast to Int32\n",
    "    items[col] = pd.to_numeric(items[col], errors='coerce').astype('Int32')\n",
    "\n",
    "# Define a list of columns that need to be converted to datetime format\n",
    "items_columns2 = ['shipping_limit_date']\n",
    "for col in items_columns2:\n",
    "    # Convert specified columns to datetime format, handle errors by setting invalid values to NaT (Not a Time)\n",
    "    items[col] = pd.to_datetime(items[col], errors='coerce')\n",
    "\n",
    "# Define a list of columns that need to be converted to float\n",
    "items_columns3 = ['price', 'transport_cost']\n",
    "for col in items_columns3:\n",
    "    # Convert specified columns to numeric (float32) and handle errors by setting invalid values to NaN\n",
    "    items[col] = pd.to_numeric(items[col], errors='coerce').astype('float32')\n",
    "\n",
    "# Display summary information about the DataFrame, including column data types and non-null counts\n",
    "items.info()\n",
    "\n",
    "# Print the number of duplicate records in the DataFrame\n",
    "print(\"\\nNumber of duplicate records:\", items.duplicated().sum())\n",
    "\n",
    "# Print the percentage of missing (null) values in each column\n",
    "print(\"\\nPercentage of null values in each column:\\n\", items.isnull().mean() * 100)\n",
    "\n",
    "# Compute and display the minimum and maximum values of the datetime columns\n",
    "items[items_columns2].agg(['min', 'max'])\n",
    "\n",
    "# Print the shape (number of rows and columns) of the DataFrame\n",
    "print(\"\\nshape:\", items.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b81ef226f3fe1789b1e8b2acac839d17</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>8</td>\n",
       "      <td>99.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9810da82917af2d9aefd1278f1dcfa0</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>24.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>65.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  payment_sequential payment_type  \\\n",
       "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
       "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
       "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
       "\n",
       "   payment_installments  payment_value  \n",
       "0                     8          99.33  \n",
       "1                     1          24.39  \n",
       "2                     1          65.71  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'payments' DataFrame\n",
    "payments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['order_id', 'payment_sequential', 'payment_type',\n",
      "       'payment_installments', 'payment_value'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  Int32  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  Int32  \n",
      " 4   payment_value         103886 non-null  float32\n",
      "dtypes: Int32(2), float32(1), object(2)\n",
      "memory usage: 3.0+ MB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " order_id                0.0\n",
      "payment_sequential      0.0\n",
      "payment_type            0.0\n",
      "payment_installments    0.0\n",
      "payment_value           0.0\n",
      "dtype: float64\n",
      "\n",
      "Unique values in payment type: ['credit_card' 'boleto' 'voucher' 'debit_card' 'not_defined']\n",
      "\n",
      "shape: (103886, 5) \n",
      "\n",
      "Unique entries: 99440\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the 'payments' DataFrame\n",
    "print(\"Columns are:\", payments.columns)\n",
    "\n",
    "# Display the data types of each column in the 'payments' DataFrame\n",
    "payments.dtypes\n",
    "\n",
    "# Define a list of columns that need to be converted to integers (with 'Int32' type)\n",
    "payments_columns1 = ['payment_sequential', 'payment_installments']\n",
    "\n",
    "# Loop through the list and convert each column to numeric values, handling errors as 'coerce' (i.e., replacing invalid values with NaN),\n",
    "# then cast the column to the 'Int32' type\n",
    "for col in payments_columns1:\n",
    "    payments[col] = pd.to_numeric(payments[col], errors='coerce').astype('Int32')\n",
    "\n",
    "# Define a list of columns that need to be converted to floating-point numbers (with 'float32' type)\n",
    "payments_columns2 = ['payment_value']\n",
    "\n",
    "# Loop through the list and convert each column to numeric values, handling errors as 'coerce',\n",
    "# then cast the column to the 'float32' type\n",
    "for col in payments_columns2:\n",
    "    payments[col] = pd.to_numeric(payments[col], errors='coerce').astype('float32')\n",
    "\n",
    "# Display information about the 'payments' DataFrame, including non-null counts and data types\n",
    "payments.info()\n",
    "\n",
    "# Print the number of duplicate records in the 'payments' DataFrame\n",
    "print(\"\\nNumber of duplicate records:\", payments.duplicated().sum())\n",
    "\n",
    "# Print the percentage of null values in each column of the 'payments' DataFrame\n",
    "print(\"\\nPercentage of null values in each column:\\n\", payments.isnull().mean() * 100)\n",
    "\n",
    "# Print the unique values found in the 'payment_type' column of the 'payments' DataFrame\n",
    "print(\"\\nUnique values in payment type:\", payments['payment_type'].unique())\n",
    "\n",
    "# Print the shape (number of rows and columns) of the 'payments' DataFrame\n",
    "print(\"\\nshape:\", payments.shape, \"\\n\")\n",
    "\n",
    "#print the unique entries\n",
    "print(\"Unique entries:\",payments['order_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>18-01-2018 00:00</td>\n",
       "      <td>18-01-2018 21:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>10-03-2018 00:00</td>\n",
       "      <td>11-03-2018 03:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>17-02-2018 00:00</td>\n",
       "      <td>18-02-2018 14:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "\n",
       "   review_score review_creation_date review_answer_timestamp  \n",
       "0             4     18-01-2018 00:00        18-01-2018 21:46  \n",
       "1             5     10-03-2018 00:00        11-03-2018 03:05  \n",
       "2             5     17-02-2018 00:00        18-02-2018 14:36  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'reviews' DataFrame\n",
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['review_id', 'order_id', 'review_score', 'review_creation_date',\n",
      "       'review_answer_timestamp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snehu\\AppData\\Local\\Temp\\ipykernel_9864\\1070584845.py:13: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  reviews[col] = pd.to_datetime(reviews[col], errors='coerce')\n",
      "C:\\Users\\snehu\\AppData\\Local\\Temp\\ipykernel_9864\\1070584845.py:13: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  reviews[col] = pd.to_datetime(reviews[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98410 entries, 0 to 98409\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   review_id                98410 non-null  object        \n",
      " 1   order_id                 98410 non-null  object        \n",
      " 2   review_score             98410 non-null  int64         \n",
      " 3   review_creation_date     98410 non-null  datetime64[ns]\n",
      " 4   review_answer_timestamp  98410 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(1), object(2)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " review_id                  0.0\n",
      "order_id                   0.0\n",
      "review_score               0.0\n",
      "review_creation_date       0.0\n",
      "review_answer_timestamp    0.0\n",
      "dtype: float64\n",
      "\n",
      "shape: (98410, 5) \n",
      "\n",
      "Unique entries: 98410\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the 'reviews' DataFrame\n",
    "print(\"Columns are:\", reviews.columns)\n",
    "\n",
    "# Display the data types of each column in the 'reviews' DataFrame\n",
    "reviews.dtypes\n",
    "\n",
    "# List of columns to convert to datetime format\n",
    "reviews_columns = ['review_creation_date', 'review_answer_timestamp']\n",
    "\n",
    "# Loop through the selected columns to convert them to datetime format\n",
    "for col in reviews_columns:\n",
    "    # Convert the column to datetime, and set errors='coerce' to handle invalid formats by assigning NaT\n",
    "    reviews[col] = pd.to_datetime(reviews[col], errors='coerce')\n",
    "\n",
    "# Display concise summary of 'reviews' DataFrame, including data types and non-null counts\n",
    "reviews.info()\n",
    "\n",
    "# Print the number of duplicate rows in the 'reviews' DataFrame\n",
    "print(\"\\nNumber of duplicate records:\", reviews.duplicated().sum())\n",
    "\n",
    "# Calculate and display the percentage of missing (null) values in each column\n",
    "print(\"\\nPercentage of null values in each column:\\n\", reviews.isnull().mean() * 100)\n",
    "\n",
    "# Drop all rows with missing values from the DataFrame\n",
    "reviews.dropna(inplace=True)\n",
    "\n",
    "# Show the minimum and maximum values of the specified datetime columns\n",
    "reviews[reviews_columns].agg(['min', 'max'])\n",
    "\n",
    "# Print the shape (number of rows and columns) of the DataFrame after cleaning\n",
    "print(\"\\nshape:\", reviews.shape, \"\\n\")\n",
    "\n",
    "#print the unique entries\n",
    "print(\"Unique entries:\",reviews['review_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_category_name_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>health_beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>computers_accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automotivo</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_category_name product_category_name_english\n",
       "0            beleza_saude                 health_beauty\n",
       "1  informatica_acessorios         computers_accessories\n",
       "2              automotivo                          auto"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 3 rows of the 'product category' DataFrame\n",
    "product_category.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: Index(['product_category_name', 'product_category_name_english'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n",
      "\n",
      "Number of duplicate records: 0\n",
      "\n",
      "Percentage of null values in each column:\n",
      " product_category_name            0.0\n",
      "product_category_name_english    0.0\n",
      "dtype: float64\n",
      "\n",
      "shape: (71, 2) \n",
      "\n",
      "Unique entries: 71\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the product_category dataframe\n",
    "print(\"Columns are:\", product_category.columns)\n",
    "\n",
    "# Print the data types of each column in the product_category dataframe\n",
    "product_category.dtypes\n",
    "\n",
    "# Display summary information about the dataframe, including the number of non-null entries for each column\n",
    "product_category.info()\n",
    "\n",
    "# Print the number of duplicate records in the dataframe\n",
    "print(\"\\nNumber of duplicate records:\", product_category.duplicated().sum())\n",
    "\n",
    "# Calculate and print the percentage of null values in each column of the dataframe\n",
    "print(\"\\nPercentage of null values in each column:\\n\", product_category.isnull().mean() * 100)\n",
    "\n",
    "# Drop rows with missing values from the dataframe and modify the dataframe in-place\n",
    "product_category.dropna(inplace=True)\n",
    "\n",
    "# Print the shape (number of rows and columns) of the dataframe after dropping null values\n",
    "print(\"\\nshape:\", product_category.shape, \"\\n\")\n",
    "\n",
    "#print the unique entries\n",
    "print(\"Unique entries:\",product_category['product_category_name'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32340, 9)\n"
     ]
    }
   ],
   "source": [
    "# Merge the 'products' DataFrame with the 'product_category' DataFrame on the 'product_category_name' column using a left join.\n",
    "df = products.merge(product_category, on='product_category_name', how='left')\n",
    "\n",
    "# Drop the 'product_category_name' column from the merged DataFrame as it is no longer needed after the join.\n",
    "df.drop(columns=['product_category_name'], inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99441, 5)\n",
      "(19015, 5)\n",
      "(99441, 7)\n"
     ]
    }
   ],
   "source": [
    "# Perform a left join between the 'customers' and 'geo_loc' DataFrames\n",
    "# Matching 'customer_zip_code_prefix' in 'customers' with 'geolocation_zip_code_prefix' in 'geo_loc'\n",
    "df1 = pd.merge(customers, geo_loc, \n",
    "               left_on='customer_zip_code_prefix', \n",
    "               right_on='geolocation_zip_code_prefix', \n",
    "               how='left')\n",
    "\n",
    "# Rename specific columns in the merged DataFrame for better readability and clarity\n",
    "df1.rename(columns={\n",
    "    'geolocation_zip_code_prefix': 'customer_zip_code1',  # Temporary column name\n",
    "    'geolocation_lat': 'customer_lat',                  # Latitude of the customer\n",
    "    'geolocation_lng': 'customer_lng',                  # Longitude of the customer\n",
    "    'geolocation_city': 'customer_city1',               # Temporary column for city\n",
    "    'geolocation_state': 'customer_state1'              # Temporary column for state\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary or temporary columns after the join\n",
    "df1.drop(columns=['customer_zip_code1', 'customer_city1', 'customer_state1'], inplace=True)\n",
    "\n",
    "# Rename 'customer_zip_code_prefix' to a more concise name 'customer_zip_code'\n",
    "df1.rename(columns={'customer_zip_code_prefix': 'customer_zip_code'}, inplace=True)\n",
    "\n",
    "print(customers.shape)\n",
    "print(geo_loc.shape)\n",
    "print(df1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'seller' and 'geo_loc' DataFrames on the 'seller_zip_code_prefix' column from 'seller' \n",
    "# and the 'geolocation_zip_code_prefix' column from 'geo_loc', using a left join to keep all rows\n",
    "# from 'seller' and only matching rows from 'geo_loc'.\n",
    "df2 = pd.merge(seller, geo_loc, \n",
    "               left_on='seller_zip_code_prefix', \n",
    "               right_on='geolocation_zip_code_prefix', \n",
    "               how='left')\n",
    "\n",
    "# Rename specific columns in 'df2' to give more meaningful names or align with conventions:\n",
    "# - Rename 'geolocation_zip_code_prefix' to 'seller_zip_code1'\n",
    "# - Rename 'geolocation_lat' to 'seller_lat'\n",
    "# - Rename 'geolocation_lng' to 'seller_lng'\n",
    "# - Rename 'geolocation_city' to 'seller_city1'\n",
    "# - Rename 'geolocation_state' to 'seller_state1'\n",
    "df2.rename(columns={\n",
    "    'geolocation_zip_code_prefix': 'seller_zip_code1', \n",
    "    'geolocation_lat': 'seller_lat',\n",
    "    'geolocation_lng': 'seller_lng',\n",
    "    'geolocation_city': 'seller_city1',\n",
    "    'geolocation_state': 'seller_state1'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns from 'df2' that were renamed but are no longer needed:\n",
    "# - 'seller_zip_code1', 'seller_city1', and 'seller_state1'\n",
    "df2.drop(columns=['seller_zip_code1', 'seller_city1', 'seller_state1'], inplace=True)\n",
    "\n",
    "# Rename the 'seller_zip_code_prefix' column in 'df1' to 'seller_zip_code'\n",
    "# to standardize naming conventions for better clarity and consistency.\n",
    "df1.rename(columns={'seller_zip_code_prefix': 'seller_zip_code'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'orders' DataFrame with the 'payments' DataFrame\n",
    "# The merge is performed on the 'order_id' column, which must exist in both DataFrames\n",
    "# The 'how=\"left\"' parameter ensures a LEFT JOIN:\n",
    "#     - All rows from the 'orders' DataFrame will be included in the result\n",
    "#     - Matching rows from the 'payments' DataFrame will be included where possible\n",
    "#     - If there's no match in 'payments', the corresponding columns will contain NaN\n",
    "df3 = orders.merge(payments, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join between the 'items' DataFrame and the 'seller' DataFrame\n",
    "df4 = items.merge(\n",
    "    seller,                # The second DataFrame to join with 'items'\n",
    "    on='seller_id',        # The common column used as the join key\n",
    "    how='left'             # Specifies a left join to keep all rows from the 'items' DataFrame\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two DataFrames: df4 and reviews\n",
    "# 'on=\"order_id\"': Specifies the common column 'order_id' to join on\n",
    "# 'how=\"left\"': Performs a left join, meaning all rows from df4 will be retained,\n",
    "#               and matching rows from the reviews DataFrame will be added.\n",
    "#               If there is no match in reviews, the result will have NaN values for those columns.\n",
    "df5 = df4.merge(reviews, on='order_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two DataFrames: df5 (left DataFrame) and df (right DataFrame)\n",
    "# Perform the merge based on the common column 'product_id'\n",
    "# Use a left join, meaning all rows from df5 will be kept, and matching rows from df will be added\n",
    "df6 = df5.merge(df, on='product_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrame df3 with df1 on the 'customer_id' column, using a left join\n",
    "# 'on' specifies the column name to join on in both DataFrames (df3 and df1)\n",
    "# 'how='left'' indicates a left join, meaning all rows from df3 will be kept, and matching rows from df1 will be included\n",
    "df7 = df3.merge(df1, on='customer_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two DataFrames (df7 and df6) on the 'order_id' column\n",
    "# using a left join to keep all rows from df7 and only matching rows from df6\n",
    "df8 = df7.merge(df6,    # df7 is the left DataFrame\n",
    "                on='order_id',   # Column 'order_id' is used as the key for merging\n",
    "                how='left')      # 'left' join ensures all rows from df7 are retained, with matching rows from df6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df8.to_csv(r'D:\\git_projects\\retail_data_analysis\\dataset\\data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>order_confirm_days</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>...</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "      <th>product_name_length</th>\n",
       "      <th>product_description_length</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "      <th>product_category_name_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>2017-10-12 03:43:00</td>\n",
       "      <td>40</td>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>500.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>housewares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>2017-10-12 03:43:00</td>\n",
       "      <td>40</td>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>500.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>housewares</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "\n",
       "  order_status order_purchase_timestamp   order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "1    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "\n",
       "  order_estimated_delivery_date  order_confirm_days  payment_sequential  ...  \\\n",
       "0                    2017-10-18            0.007431                   1  ...   \n",
       "1                    2017-10-18            0.007431                   3  ...   \n",
       "\n",
       "  review_creation_date  review_answer_timestamp  product_name_length  \\\n",
       "0           2017-10-11      2017-10-12 03:43:00                   40   \n",
       "1           2017-10-11      2017-10-12 03:43:00                   40   \n",
       "\n",
       "  product_description_length  product_photos_qty product_weight_g  \\\n",
       "0                        268                   4            500.0   \n",
       "1                        268                   4            500.0   \n",
       "\n",
       "  product_length_cm  product_height_cm  product_width_cm  \\\n",
       "0              19.0                8.0              13.0   \n",
       "1              19.0                8.0              13.0   \n",
       "\n",
       "   product_category_name_english  \n",
       "0                     housewares  \n",
       "1                     housewares  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
